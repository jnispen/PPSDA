{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario B - Baseline Variation\n",
    "\n",
    "In this scenario the baseline underlying a spectrum with a fixed number of peaks (3) is varied between no baseline, a constant offset and a linear baseline. The noise level is kept constant at 1%.\n",
    "\n",
    "The models used in the inference of the parameters are formulated as follows:\n",
    "\n",
    "1. No baseline:\n",
    "\\begin{equation}\n",
    "\\large y = f(x) = \\sum\\limits_{m=1}^M \\big[A_m \\cdot e^{-\\frac{(x-\\mu_m)^2}{2\\cdot\\sigma_m^2}}\\big] + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "2. Constant offset:\n",
    "\\begin{equation}\n",
    "\\large y = f(x) = \\sum\\limits_{m=1}^M \\big[A_m \\cdot e^{-\\frac{(x-\\mu_m)^2}{2\\cdot\\sigma_m^2}}\\big] + a_0 + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "3. Linear baseline:\n",
    "\\begin{equation}\n",
    "\\large y = f(x) = \\sum\\limits_{m=1}^M \\big[A_m \\cdot e^{-\\frac{(x-\\mu_m)^2}{2\\cdot\\sigma_m^2}}\\big] + a_0 + a_1 \\cdot x + \\epsilon\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "#az.style.use('arviz-darkgrid')\n",
    "\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../modules')\n",
    "import datagen as dg\n",
    "import models as mdl\n",
    "import results as res\n",
    "import figures as fig\n",
    "import settings as cnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for results and images\n",
    "out_path      = './output_baseline'\n",
    "file_basename = out_path + '/scenario_baseline'\n",
    "        \n",
    "# if dir does not exist, create it\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "conf = {}\n",
    "    \n",
    "# scenario name\n",
    "conf['scenario'] = 'baseline variation'\n",
    "    \n",
    "# initialization method for sampler\n",
    "conf['init_mode'] = 'adapt_diag'\n",
    "\n",
    "# probabilistic model (priors)\n",
    "conf['prior_model'] = 'lognormal'\n",
    "\n",
    "# provide peak positions to the model as testvalues ('yes'/'no')\n",
    "conf['peak_info'] = 'yes'\n",
    "\n",
    "# model mode ('train'/eval')\n",
    "conf['model_mode'] = 'train'\n",
    "\n",
    "# data mode ('generate'/'preload')\n",
    "conf['data_mode'] = 'generate'\n",
    "\n",
    "# dataset directory (needed for 'preload' data mode)\n",
    "#conf['dataset_dir'] = './input_datasets'\n",
    "\n",
    "# number of cores to run sampling chains on\n",
    "conf['ncores'] = 2\n",
    "\n",
    "# number of samples per chain\n",
    "conf['nsamples'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.save(out_path, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of wavelengths (x-values)\n",
    "xval = [i for i in range(200, 400, 2)]\n",
    "\n",
    "ldata  = []\n",
    "lpeaks = []\n",
    "lbline = []\n",
    "\n",
    "# number of spectra per baseline variation\n",
    "nsets  = 1\n",
    "\n",
    "# baseline variation\n",
    "baselines = ['none', 'offset']\n",
    "#baselines = ['none', 'offset', 'linear']\n",
    "\n",
    "lbline = [bl for bl in baselines for i in range(nsets)]\n",
    "\n",
    "# total number of datasets\n",
    "tsets = nsets * len(baselines)\n",
    "        \n",
    "if conf['model_mode'] == 'train' and conf['data_mode'] == 'generate':\n",
    "    # generate the datasets\n",
    "    for blv in baselines:\n",
    "        for i in range(nsets):\n",
    "            df, peaks, _ = dg.data_generator(xvalues=xval, nsamples=15, npeaks=3, tbaseline=blv)\n",
    "            ldata.append(df)\n",
    "            lpeaks.append(peaks)\n",
    "    # save data and peak information to disk\n",
    "    for i in range(len(ldata)):\n",
    "        ldata[i].to_csv(out_path + '/dataset_%02d.csv' % (i+1), index=False)\n",
    "    dg.data_save(out_path + '/peakinfo.csv', lpeaks)\n",
    "        \n",
    "elif conf['model_mode'] == 'train' and conf['data_mode'] == 'preload':           \n",
    "    # load pre-generated datasets from disk\n",
    "    ldata, lpeaks, _ = dg.data_load(tsets, conf['dataset_dir'])\n",
    "    \n",
    "else:        \n",
    "    # load data from disk\n",
    "    if conf['data_mode'] == 'preload':\n",
    "        ldata, lpeaks, _ = dg.data_load(tsets, conf['dataset_dir'])\n",
    "    else:\n",
    "        ldata, lpeaks, _ = dg.data_load(tsets, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"total number of baseline variations     : {0}\".format(len(baselines)))\n",
    "print(\"total number of spectra per baseline    : {0}\".format(nsets))\n",
    "print(\"total number of datasets per model      : {0}\".format(tsets))\n",
    "print(\"total number of inference runs          : {0}\".format(nsets*len(baselines)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot datasets\n",
    "fig.plot_datasets(ldata, lpeaks, dims=(int(tsets/2),2), figure_size=(12,int(tsets*(1.8))), \n",
    "                            savefig='yes', fname=file_basename, title='baseline', baselines=lbline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas data to numpy arrays\n",
    "x_val = np.array(xval, dtype='float32')\n",
    "\n",
    "# store dataset y-values in list\n",
    "cols = ldata[0].columns\n",
    "y_val = [ldata[i][cols].values for i in range(len(ldata))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize models and run inference\n",
    "models = []\n",
    "traces = []\n",
    "\n",
    "# actual run number\n",
    "run = 1\n",
    "\n",
    "# total number of inference runs\n",
    "truns = nsets * len(baselines)**2\n",
    "\n",
    "for bl in baselines:\n",
    "    if conf['model_mode'] == 'train':\n",
    "        # for each baseline model run inference on all spectra\n",
    "        print(\"running baseline-{0} model\".format(bl))\n",
    "    \n",
    "    for i in range(len(ldata)):\n",
    "        if conf['peak_info'] == 'yes':\n",
    "            plist = lpeaks[i].flatten()\n",
    "            plist.sort()\n",
    "            model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=3, \n",
    "                                  mu_peaks=plist, pmodel=conf['prior_model'], baseline=bl)\n",
    "        else:\n",
    "            model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=3,\n",
    "                                                  pmodel=conf['prior_model'], baseline=bl)\n",
    "        models.append(model_g)\n",
    "\n",
    "        with model_g:\n",
    "            if conf['model_mode'] == 'train':\n",
    "                print(\"({2}/{3}) running inference on dataset #{0}/{1} [{4} model: {5} spectrum]\"\n",
    "                      .format(i+1,len(ldata),run,truns,bl,lbline[i]))\n",
    "                trace_g = pm.sample(conf['nsamples'], init=conf['init_mode'], cores=conf['ncores'])\n",
    "                # [model baseline-none: baseline-none spectrum]\n",
    "                traces.append(trace_g)\n",
    "                # save inference results\n",
    "                pm.backends.text.dump(out_path + '/traces_%02d' % (run), trace_g)\n",
    "            else:\n",
    "                # load traces from disk\n",
    "                print(\"loading dataset #{0}/{1}\".format(run,truns))\n",
    "                trace_g = pm.backends.text.load(out_path + '/traces_%02d' % (run))\n",
    "                traces.append(trace_g)\n",
    "            run += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(models[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model figure as image\n",
    "img = pm.model_to_graphviz(models[0])\n",
    "img.render(filename=file_basename + '_model', format='png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive traces\n",
    "ppc = [pm.sample_posterior_predictive(traces[i], samples=500, model=models[i]) for i in range(len(traces))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# various plots to inspect the inference results\n",
    "varnames = ['amp', 'mu', 'sigma', 'epsilon']\n",
    "\n",
    "#az.plot_trace(traces[2], varnames, compact=True);\n",
    "#az.plot_trace(traces[2], varnames, divergences='top');\n",
    "#az.plot_autocorr(traces[0], varnames);\n",
    "#az.plot_posterior(traces[2], varnames);\n",
    "\n",
    "#for idx, trace in enumerate(traces):\n",
    "#    az.plot_forest(trace, var_names = varnames, r_hat=True, ess=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if conf['model_mode'] == 'train':\n",
    "    # collect the results and display\n",
    "    df = res.get_results_summary(varnames, traces, ppc, y_val, epsilon_real=0.05, sets=tsets, labels=lmodpeak)\n",
    "else:\n",
    "    # load results from disk\n",
    "    df = pd.read_csv(file_basename + '.csv')\n",
    "    df.index += 1\n",
    "#df.sort_values(by=['r2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['model_mode'] == 'train':\n",
    "    # save results to .csv\n",
    "    df.to_csv(file_basename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(int(truns/2),2), figure_size=(12,int(truns*(1.8))),\n",
    "                    savefig='yes', fname=file_basename, showpeaks='no', sets=tsets, labels=lmodpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(int(truns/2),2), figure_size=(12,int(truns*(1.8))),\n",
    "                    savefig='yes', fname=file_basename, showpeaks='yes', sets=tsets, labels=lmodpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.close(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
