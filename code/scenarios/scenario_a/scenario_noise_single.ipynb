{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario A - Noise Level Variation (individual dataset)\n",
    "\n",
    "This file is used to zoom in and experiment on on a previously generated dataset.\n",
    "\n",
    "The model used in the inference of the parameters is formulated as follows: \n",
    "\n",
    "\\begin{equation}\n",
    "\\large y = f(x) = \\sum\\limits_{m=1}^M \\big[A_m \\cdot e^{-\\frac{(x-\\mu_m)^2}{2\\cdot\\sigma_m^2}}\\big] + \\epsilon\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "#az.style.use('arviz-darkgrid')\n",
    "\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import local utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../utils')\n",
    "import utils as utl\n",
    "import datagen as dg\n",
    "import models as mdl\n",
    "import results as res\n",
    "import figures as fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset to load\n",
    "ndata = '06'\n",
    "input_datafile = './input_datasets/dataset_'+ str(ndata) + '.csv' \n",
    "input_peakfile = './input_datasets/peakinfo.csv' \n",
    "\n",
    "# output for results and images\n",
    "out_path = './output_' + str(ndata) + '/'\n",
    "fbase    = 'scenario_noise' + str(ndata)\n",
    "file_basename = out_path + fbase\n",
    "\n",
    "# if dir does not exist, create it\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "# initialization method for sampler ('jitter+adapt_diag'/'advi+adapt_diag'/'adapt_diag')\n",
    "init_mode = 'adapt_diag'\n",
    "    \n",
    "# provide peak positions to the model as testvalues ('yes'/'no')\n",
    "peak_info = 'yes'\n",
    "\n",
    "# model mode ('train')\n",
    "model_mode = 'train'\n",
    "\n",
    "# number of times to run inference engine on dataset\n",
    "niter = 4\n",
    "\n",
    "# number of cores to run\n",
    "ncores = 2\n",
    "\n",
    "# number of samples per chain\n",
    "nsamples = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(out_path + 'settings.txt', 'w')\n",
    "fp.write('start : ' + datetime.datetime.now().strftime(\"%A, %d. %B %Y %I:%M%p\") + '\\n')\n",
    "fp.write('input file = ' + input_datafile + '\\n')\n",
    "fp.write('init_mode  = ' + init_mode + '\\n')\n",
    "fp.write('peak_info  = ' + peak_info + '\\n')\n",
    "fp.write('ncores     = ' + str(ncores) + '\\n')\n",
    "fp.write('nsamples   = ' + str(nsamples) + '\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ldata  = []\n",
    "lpeaks = []\n",
    "\n",
    "# load data from disk\n",
    "print(\"loading file {0}\".format(input_datafile))\n",
    "df = pd.read_csv(input_datafile)\n",
    "ldata.append(df)\n",
    "print(\"loading peakinfo {0}\".format(input_peakfile))\n",
    "pks = np.loadtxt(input_peakfile, delimiter=',')\n",
    "lpeaks.append(pks[int(ndata)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot datasets\n",
    "fig.plot_datasets(ldata, lpeaks, dims=(1,1), figure_size=(8,6), savefig='yes', fname=file_basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand dataframe and peak list\n",
    "for i in range(niter-1):\n",
    "    ldata.append(ldata[0])\n",
    "    lpeaks.append(lpeaks[0])\n",
    "    \n",
    "# convert pandas data to numpy arrays\n",
    "x_val = np.array(ldata[0].columns.to_list(), dtype='float32')\n",
    "\n",
    "# store dataset y-values in list\n",
    "cols = ldata[0].columns\n",
    "y_val = [ldata[i][cols].values for i in range(len(ldata))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize models and run inference\n",
    "models = []\n",
    "traces = []\n",
    "\n",
    "for i in range(len(ldata)):\n",
    "        if peak_info == 'yes':\n",
    "            plist = lpeaks[i].flatten()\n",
    "            plist.sort()\n",
    "            model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=3, mu_peaks=plist)\n",
    "        else:\n",
    "            model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=3) \n",
    "        models.append(model_g)\n",
    "\n",
    "        with model_g:\n",
    "            if model_mode == 'train':\n",
    "                print(\"running inference on dataset #{0}/{1}\".format(i+1,len(ldata)))\n",
    "                trace_g = pm.sample(nsamples, init=init_mode, cores=ncores)\n",
    "                traces.append(trace_g)\n",
    "                # save inference results\n",
    "                pm.backends.text.dump(out_path + '/traces_%02d' % (i+1), trace_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model figure as image\n",
    "img = pm.model_to_graphviz(models[0])\n",
    "img.render(filename=file_basename + '_model', format='png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive traces\n",
    "ppc = [pm.sample_posterior_predictive(traces[i], samples=500, model=models[i]) for i in range(len(traces))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# various plots to inspect the inference results\n",
    "varnames = ['amp', 'mu', 'sigma', 'epsilon']\n",
    "\n",
    "#az.summary(traces[0], varnames)\n",
    "#az.plot_trace(traces[2], varnames, compact=True);\n",
    "#az.plot_trace(traces[2], varnames, divergences='top');\n",
    "#az.plot_autocorr(traces[0], varnames);\n",
    "#az.plot_posterior(traces[2], varnames);\n",
    "\n",
    "#for idx, trace in enumerate(traces):\n",
    "#    az.plot_forest(trace, var_names = varnames, r_hat=True, ess=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#az.plot_trace(traces[0], varnames, compact=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_mode == 'train':\n",
    "    # collect the results and display\n",
    "    df = res.get_results_summary(varnames, traces, ppc, y_val)\n",
    "else:\n",
    "    # load results from disk\n",
    "    df = pd.read_csv(file_basename + '.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_mode == 'train':\n",
    "    # save results to .csv\n",
    "    df.to_csv(file_basename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(int(niter/2),2), figure_size=(16,12), savefig='yes', \n",
    "                       fname=file_basename, showpeaks='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(int(niter/2),2), figure_size=(16,12), savefig='yes', \n",
    "                       fname=file_basename, showpeaks='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(out_path + 'settings.txt', 'a')\n",
    "fp.write('stop : ' + datetime.datetime.now().strftime(\"%A, %d. %B %Y %I:%M%p\") + '\\n')\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
