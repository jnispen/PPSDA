{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario A - Noise Level Variation\n",
    "\n",
    "In this scenario the noise level on a generated dataset is varied in three steps: low/medium/high, \n",
    "the rest of the parameters in the dataset is kept constant.\n",
    "\n",
    "The model used in the inference of the parameters is formulated as follows: \n",
    "\n",
    "\\begin{equation}\n",
    "\\large y = f(x) = \\sum\\limits_{m=1}^M \\big[A_m \\cdot e^{-\\frac{(x-\\mu_m)^2}{2\\cdot\\sigma_m^2}}\\big] + \\epsilon\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "#az.style.use('arviz-darkgrid')\n",
    "\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import local utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../utils')\n",
    "import utils as utl\n",
    "import datagen as dg\n",
    "import models as mdl\n",
    "import results as res\n",
    "import figures as fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for results and images\n",
    "out_path      = './output_nopeak_adapt_diag/'\n",
    "fbase         = 'scenario_noise'\n",
    "file_basename = out_path + fbase\n",
    "        \n",
    "# if dir does not exist, create it\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "# initialization method for sampler ('jitter+adapt_diag'/'advi+adapt_diag'/'adapt_diag')\n",
    "init_mode = 'adapt_diag'\n",
    "    \n",
    "# provide peak positions to the model as testvalues ('yes'/'no')\n",
    "peak_info = 'no'\n",
    "\n",
    "# model mode ('train'/eval')\n",
    "model_mode = 'train'\n",
    "\n",
    "# data mode ('generate'/'preload')\n",
    "data_mode = 'preload'\n",
    "\n",
    "# dataset directory\n",
    "dataset_dir = './input_datasets'\n",
    "\n",
    "# number of cores to run sampling chains on\n",
    "ncores = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(out_path + 'settings.txt', 'w')\n",
    "fp.write('start: ' + datetime.datetime.now().strftime(\"%A, %d. %B %Y %I:%M%p\") + '\\n')\n",
    "fp.write('init_mode  = ' + init_mode + '\\n')\n",
    "fp.write('peak_info  = ' + peak_info + '\\n')\n",
    "fp.write('model_mode = ' + model_mode + '\\n')\n",
    "fp.write('data_mode  = ' + data_mode + '\\n')\n",
    "if data_mode == 'preload':\n",
    "    fp.write('data_dir   = ' + dataset_dir + '\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of wavelengths (x-values)\n",
    "xval = [i for i in range(200, 400, 2)]\n",
    "\n",
    "ldata  = []\n",
    "lpeaks = []\n",
    "lnoise = []\n",
    "nsets  = 10\n",
    "\n",
    "# noise level is 1%, 2% and 5% of the minimal signal amplitude\n",
    "noise_levels = [0.05, 0.10, 0.25]\n",
    "\n",
    "# total number of datasets\n",
    "tsets = nsets * len(noise_levels)\n",
    "\n",
    "# real noise level list\n",
    "for nl in noise_levels:\n",
    "    for i in range(nsets):\n",
    "        lnoise.append(nl)\n",
    "        \n",
    "if model_mode == 'train' and data_mode == 'generate':\n",
    "    # generate the datasets\n",
    "    for nl in noise_levels:\n",
    "        for i in range(nsets):\n",
    "            df, peaks = dg.data_generator(xvalues=xval, nsamples=15, noise=nl)\n",
    "            ldata.append(df)\n",
    "            lpeaks.append(peaks)\n",
    "    # save data to disk\n",
    "    for i in range(len(ldata)):\n",
    "        ldata[i].to_csv(out_path + '/dataset_%02d.csv' % (i+1), index=False)\n",
    "        np.savetxt(out_path + '/peakinfo.csv', lpeaks, delimiter=',')\n",
    "        \n",
    "elif model_mode == 'train' and data_mode == 'preload':           \n",
    "    # load pre-generated datasets from disk\n",
    "    ldata, lpeaks = dg.data_load(tsets, dataset_dir)\n",
    "    \n",
    "else:        \n",
    "    # load data from disk\n",
    "    if data_mode == 'preload':\n",
    "        ldata, lpeaks = dg.data_load(tsets, dataset_dir)\n",
    "    else:\n",
    "        ldata, lpeaks = dg.data_load(tsets, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot datasets\n",
    "fig.plot_datasets(ldata, lpeaks, dims=(15,2), figure_size=(12,48), savefig='yes', fname=file_basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas data to numpy arrays\n",
    "x_val = np.array(xval, dtype='float32')\n",
    "\n",
    "# store dataset y-values in list\n",
    "cols = ldata[0].columns\n",
    "y_val = [ldata[i][cols].values for i in range(len(ldata))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize models and run inference\n",
    "models = []\n",
    "traces = []\n",
    "\n",
    "for i in range(len(ldata)):\n",
    "    if peak_info == 'yes':\n",
    "        plist = lpeaks[i].flatten()\n",
    "        plist.sort()\n",
    "        model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=3, mu_peaks=plist)\n",
    "    else:\n",
    "        model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=3)      \n",
    "    models.append(model_g)\n",
    "    \n",
    "    with model_g:\n",
    "        if model_mode == 'train':\n",
    "            print(\"running inference on dataset #{0}/{1}\".format(i+1,len(ldata)))\n",
    "            trace_g = pm.sample(2000, init=init_mode, cores=ncores)\n",
    "            traces.append(trace_g)\n",
    "            # save inference results\n",
    "            pm.backends.text.dump(out_path + '/traces_%02d' % (i+1), trace_g)\n",
    "        else:\n",
    "            # load traces from disk\n",
    "            print(\"loading dataset #{0}/{1}\".format(i+1,len(ldata)))\n",
    "            trace_g = pm.backends.text.load(out_path + '/traces_%02d' % (i+1))\n",
    "            traces.append(trace_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model figure as image\n",
    "img = pm.model_to_graphviz(models[0])\n",
    "img.render(filename=file_basename + '_model', format='png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive traces\n",
    "ppc = [pm.sample_posterior_predictive(traces[i], samples=500, model=models[i]) for i in range(len(traces))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# various plots to inspect the inference results\n",
    "varnames = ['amp', 'mu', 'sigma', 'epsilon']\n",
    "\n",
    "#az.plot_trace(traces[2], varnames, compact=True);\n",
    "#az.plot_trace(traces[2], varnames, divergences='top');\n",
    "#az.plot_autocorr(traces[0], varnames);\n",
    "#az.plot_posterior(traces[2], varnames);\n",
    "\n",
    "#for idx, trace in enumerate(traces):\n",
    "#    az.plot_forest(trace, var_names = varnames, r_hat=True, ess=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_mode == 'train':\n",
    "    # collect the results and display\n",
    "    df = res.get_results_summary(varnames, traces, ppc, y_val, epsilon_real=lnoise)\n",
    "else:\n",
    "    # load results from disk\n",
    "    df = pd.read_csv(file_basename + '.csv')\n",
    "    df.index += 1\n",
    "#df.sort_values(by=['r2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_mode == 'train':\n",
    "    # save results to .csv\n",
    "    df.to_csv(file_basename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(15,2), figure_size=(12,48), savefig='yes', \n",
    "                       fname=file_basename, showpeaks='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(15,2), figure_size=(12,48), savefig='yes', \n",
    "                       fname=file_basename, showpeaks='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(out_path + 'settings.txt', 'a')\n",
    "fp.write('stop : ' + datetime.datetime.now().strftime(\"%A, %d. %B %Y %I:%M%p\") + '\\n')\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
