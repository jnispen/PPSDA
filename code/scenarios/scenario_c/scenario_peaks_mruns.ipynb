{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario C - Peak Number Variation (multiple runs)\n",
    "\n",
    "In this scenario the number of peaks in a generated dataset is varied from low to high, \n",
    "the rest of the parameters is kept constant (noise level = 1%). The number of peaks expected by the probabilistic model is varied between the low and high peak number.\n",
    "\n",
    "The model used in the inference of the parameters is formulated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large y = f(x) = \\sum\\limits_{m=1}^M \\big[A_m \\cdot e^{-\\frac{(x-\\mu_m)^2}{2\\cdot\\sigma_m^2}}\\big] + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "This file runs a series of inference runs for a set of generated spectra. New spectra are generated for each run and stored. After running inference, only the summary statistics are stored and the next run is started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "#az.style.use('arviz-darkgrid')\n",
    "\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../modules')\n",
    "import datagen as dg\n",
    "import models as mdl\n",
    "import results as res\n",
    "import figures as fig\n",
    "import settings as cnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for results and images\n",
    "out_path      = './output_mruns_5x5'\n",
    "file_basename = out_path + '/scenario_peaks'\n",
    "        \n",
    "# if dir does not exist, create it\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "conf = {}\n",
    "    \n",
    "# scenario name\n",
    "conf['scenario'] = 'peak variation'\n",
    "    \n",
    "# initialization method for sampler\n",
    "conf['init_mode'] = 'adapt_diag'\n",
    "\n",
    "# probabilistic model (priors)\n",
    "conf['prior_model'] = 'lognormal'\n",
    "\n",
    "# provide peak positions to the model as testvalues ('yes'/'no')\n",
    "conf['peak_info'] = 'yes'\n",
    "\n",
    "# data mode ('generate'/'preload')\n",
    "conf['data_mode'] = 'generate'\n",
    "\n",
    "# number of runs\n",
    "conf['nruns'] = 4\n",
    "\n",
    "# number of cores to run sampling chains on\n",
    "conf['ncores'] = 2\n",
    "\n",
    "# number of samples per chain\n",
    "conf['nsamples'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.save(out_path, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of wavelengths (x-values)\n",
    "xval = [i for i in range(200, 400, 2)]\n",
    "\n",
    "# number of spectra per peak number\n",
    "nsets  = 4\n",
    "\n",
    "# number of peaks in the spectrum\n",
    "peak_numbers = [2,3,4,5,6]\n",
    "\n",
    "# total number of datasets\n",
    "tsets = nsets * len(peak_numbers)\n",
    "\n",
    "# total number of inference runs (per run)\n",
    "truns = nsets * len(peak_numbers)**2\n",
    "\n",
    "# generate nruns sets of spectra\n",
    "for r in range(conf['nruns']):\n",
    "    print(\"Generating dataset {0} of {1}\".format(r+1,conf['nruns']))\n",
    "    \n",
    "    ldata, lpeaks, lpeakdata  = [], [], []\n",
    "    \n",
    "    # create output directory for data\n",
    "    out_dir = out_path + '/run_{0:02d}'.format(r+1)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "            \n",
    "    for pn in peak_numbers:\n",
    "        for i in range(nsets):\n",
    "            df, peaks, df_peakinfo = dg.data_generator(xvalues=xval, nsamples=15, npeaks=pn)\n",
    "            ldata.append(df)\n",
    "            lpeaks.append(peaks)\n",
    "            lpeakdata.append(df_peakinfo)\n",
    "            \n",
    "    # save data and peak information to disk\n",
    "    for i in range(len(ldata)):\n",
    "        ldata[i].to_csv(out_dir + '/dataset_{0:02d}.csv'.format(i+1), index=False)\n",
    "        lpeakdata[i].to_csv(out_dir + '/peakdata_{0:02d}.csv'.format(i+1), index=False)\n",
    "    dg.data_save(out_dir + '/peakinfo.csv', lpeaks)\n",
    "    \n",
    "    # plot datasets\n",
    "    filen = out_dir + '/scenario_peaks'\n",
    "    fig.plot_datasets(ldata, lpeaks, dims=(int(tsets/2),2), figure_size=(12,int(tsets*(1.8))), \n",
    "                                                        savefig='yes', fname=filen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of multiple runs                    : {0}\".format(conf['nruns']))\n",
    "print(\"total number of peak numbers                     : {0}\".format(len(peak_numbers)))\n",
    "print(\"total number of datasets per peak number         : {0}\".format(nsets))\n",
    "print(\"total number of datasets per model               : {0}\".format(tsets))\n",
    "print(\"total number of inference runs (per single loop) : {0}\".format(truns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, run inference, visualize, collect results and save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas data to numpy arrays\n",
    "x_val = np.array(xval, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataframe to hold multiple run results\n",
    "res_df = pd.DataFrame()\n",
    "\n",
    "# run the whole loop of inference, posterior sampling, results collection and saving\n",
    "for r in range(conf['nruns']):\n",
    "    print(\"starting loop {0}/{1}\".format(r+1,conf['nruns']))\n",
    "\n",
    "    models, traces, lmodpeak = [], [], []\n",
    "\n",
    "    # load datasets from disk\n",
    "    data_dir = out_path + '/run_{0:02d}'.format(r+1)\n",
    "    ldata, lpeaks, lpeakdata = dg.data_load(tsets, data_dir)\n",
    "\n",
    "    # store dataset y-values in list\n",
    "    cols = ldata[0].columns\n",
    "    y_val = [ldata[i][cols].values for i in range(len(ldata))]\n",
    "\n",
    "    # actual inference run number\n",
    "    inf_run = 1\n",
    "\n",
    "    for pn in peak_numbers:\n",
    "        print(\"running {0}-peak model\".format(pn))\n",
    "        for i in range(len(ldata)):\n",
    "            if conf['peak_info'] == 'yes':\n",
    "                # Get the peak numbers from the list. If the actual peak number in the spectrum is \n",
    "                # lower than what the model is expecting, then expand the list to the expected size,\n",
    "                # duplicating the existing peak mu values, else truncate the list (taking the peaks\n",
    "                # with the highest amplitude).\n",
    "                plist = sorted(lpeaks[i])\n",
    "                if len(plist) < pn:\n",
    "                    pl = sorted(np.resize(plist, (1,pn)).flatten())\n",
    "                else:\n",
    "                    # sort peak info dataframe on amplitude value \n",
    "                    l1 = lpeakdata[i].sort_values('amp', ascending=False)\n",
    "                    # truncate list to expected peak number\n",
    "                    pl = l1['mu'].values[:pn]\n",
    "\n",
    "                model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=pn, \n",
    "                                          mu_peaks=pl, pmodel=conf['prior_model'])\n",
    "            else:\n",
    "                model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=pn,\n",
    "                                          pmodel=conf['prior_model'])      \n",
    "            models.append(model_g)\n",
    "\n",
    "            with model_g:\n",
    "                print(\"({6}:{2}/{3}) running inference on dataset #{0}/{1} [{4}-peak model:{5}-peak spectrum]\"\n",
    "                      .format(i+1,len(ldata),inf_run,truns,pn,len(plist),r+1))\n",
    "                lmodpeak += [(pn,len(plist))]\n",
    "                trace_g = pm.sample(conf['nsamples'], init=conf['init_mode'], cores=conf['ncores'])\n",
    "                traces.append(trace_g)\n",
    "                inf_run += 1\n",
    "\n",
    "    # save model figure as image (once)\n",
    "    if r == 0:\n",
    "        img = pm.model_to_graphviz(models[0])\n",
    "        img.render(filename=file_basename + '_model', format='png');\n",
    "\n",
    "    # posterior predictive traces\n",
    "    ppc = [pm.sample_posterior_predictive(traces[i], samples=500, model=models[i]) for i in range(len(traces))]\n",
    "\n",
    "    # collect the results, concat single run result to overall result \n",
    "    varnames = ['amp', 'mu', 'sigma', 'epsilon']\n",
    "    lruns = ['{0}'.format(r+1) for i in range(truns)]\n",
    "    df = res.get_results_summary(varnames, traces, ppc, y_val, epsilon_real=0.05, sets=tsets, \n",
    "                                 labels=lmodpeak, runlist=lruns)\n",
    "    \n",
    "    res_df = res_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to .csv\n",
    "res_df.to_csv(out_path + '/scenario_peaks_mruns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.close(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
