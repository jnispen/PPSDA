{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario C - Peak Number Variation\n",
    "\n",
    "In this scenario the number of peaks in a generated dataset is varied in from low to high (e.g. 2-6), \n",
    "the rest of the parameters is kept constant (noise level = 1%). The number of peaks expected by the probabilistic model is varied between the low and high peak number.\n",
    "\n",
    "The model used in the inference of the parameters is formulated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large y = f(x) = \\sum\\limits_{m=1}^M \\big[A_m \\cdot e^{-\\frac{(x-\\mu_m)^2}{2\\cdot\\sigma_m^2}}\\big] + \\epsilon\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "#az.style.use('arviz-darkgrid')\n",
    "\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../modules')\n",
    "import datagen as dg\n",
    "import models as mdl\n",
    "import results as res\n",
    "import figures as fig\n",
    "import settings as cnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for results and images\n",
    "out_path      = './output_peaks_5x5'\n",
    "file_basename = out_path + '/scenario_peaks'\n",
    "        \n",
    "# if dir does not exist, create it\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "conf = {}\n",
    "    \n",
    "# scenario name\n",
    "conf['scenario'] = 'peak variation'\n",
    "    \n",
    "# initialization method for sampler\n",
    "conf['init_mode'] = 'adapt_diag'\n",
    "\n",
    "# probabilistic model (priors)\n",
    "conf['prior_model'] = 'lognormal'\n",
    "\n",
    "# provide peak positions to the model as testvalues ('yes'/'no')\n",
    "conf['peak_info'] = 'yes'\n",
    "\n",
    "# model mode ('train'/eval')\n",
    "conf['model_mode'] = 'train'\n",
    "\n",
    "# data mode ('generate'/'preload')\n",
    "conf['data_mode'] = 'generate'\n",
    "\n",
    "# dataset directory (needed for 'preload' data mode)\n",
    "#conf['dataset_dir'] = './input_datasets'\n",
    "\n",
    "# number of cores to run sampling chains on\n",
    "conf['ncores'] = 2\n",
    "\n",
    "# number of samples per chain\n",
    "conf['nsamples'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.save(out_path, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of wavelengths (x-values)\n",
    "xval = [i for i in range(200, 400, 2)]\n",
    "\n",
    "ldata  = []\n",
    "lpeaks = []\n",
    "lpeakdata = []\n",
    "\n",
    "# number of spectra per peak number\n",
    "nsets  = 1\n",
    "\n",
    "# number of peaks in the spectrum\n",
    "peak_numbers = [2,3]\n",
    "\n",
    "# total number of datasets\n",
    "tsets = nsets * len(peak_numbers)\n",
    "        \n",
    "if conf['model_mode'] == 'train' and conf['data_mode'] == 'generate':\n",
    "    # generate the datasets\n",
    "    for pn in peak_numbers:\n",
    "        for i in range(nsets):\n",
    "            df, peaks, df_peakinfo = dg.data_generator(xvalues=xval, nsamples=15, npeaks=pn)\n",
    "            ldata.append(df)\n",
    "            lpeaks.append(peaks)\n",
    "            lpeakdata.append(df_peakinfo)\n",
    "    # save data and peak information to disk\n",
    "    for i in range(len(ldata)):\n",
    "        ldata[i].to_csv(out_path + '/dataset_%02d.csv' % (i+1), index=False)\n",
    "        lpeakdata[i].to_csv(out_path + '/peakdata_%02d.csv' % (i+1), index=False)\n",
    "    dg.data_save(out_path + '/peakinfo.csv', lpeaks)\n",
    "        \n",
    "elif conf['model_mode'] == 'train' and conf['data_mode'] == 'preload':           \n",
    "    # load pre-generated datasets from disk\n",
    "    ldata, lpeaks, lpeakdata = dg.data_load(tsets, conf['dataset_dir'])\n",
    "    \n",
    "else:        \n",
    "    # load data from disk\n",
    "    if conf['data_mode'] == 'preload':\n",
    "        ldata, lpeaks, lpeakdata = dg.data_load(tsets, conf['dataset_dir'])\n",
    "    else:\n",
    "        ldata, lpeaks, lpeakdata = dg.data_load(tsets, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"total number of peak numbers            : {0}\".format(len(peak_numbers)))\n",
    "print(\"total number of spectra per peak number : {0}\".format(nsets))\n",
    "print(\"total number of datasets per model      : {0}\".format(tsets))\n",
    "print(\"total number of inference runs          : {0}\".format(nsets*len(peak_numbers)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot datasets\n",
    "fig.plot_datasets(ldata, lpeaks, dims=(int(tsets/2),2), figure_size=(12,int(tsets*(1.8))), \n",
    "                                                        savefig='yes', fname=file_basename, title='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas data to numpy arrays\n",
    "x_val = np.array(xval, dtype='float32')\n",
    "\n",
    "# store dataset y-values in list\n",
    "cols = ldata[0].columns\n",
    "y_val = [ldata[i][cols].values for i in range(len(ldata))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize models and run inference\n",
    "models = []\n",
    "traces = []\n",
    "\n",
    "# list of tuples with (model,peak) combination\n",
    "lmodpeak = []\n",
    "\n",
    "# actual run number\n",
    "run = 1\n",
    "\n",
    "# total number of inference runs\n",
    "truns = nsets * len(peak_numbers)**2\n",
    "\n",
    "for pn in peak_numbers:\n",
    "    if conf['model_mode'] == 'train':\n",
    "        # for each model (from low-high peak number) run inference on all spectra\n",
    "        print(\"running {0}-peak model\".format(pn))\n",
    "    \n",
    "    for i in range(len(ldata)):\n",
    "        if conf['peak_info'] == 'yes':\n",
    "            # Get the peak numbers from the list. If the actual peak number in the spectrum is \n",
    "            # lower than what the model is expecting, then expand the list to the expected size,\n",
    "            # duplicating the existing peak mu values, else truncate the list (taking the peaks\n",
    "            # with the highest amplitude).\n",
    "            plist = sorted(lpeaks[i])\n",
    "            if len(plist) < pn:\n",
    "                pl = sorted(np.resize(plist, (1,pn)).flatten())\n",
    "            else:\n",
    "                # sort peak info dataframe on amplitude value \n",
    "                l1 = lpeakdata[i].sort_values('amp', ascending=False)\n",
    "                # truncate list to expected peak number\n",
    "                pl = l1['mu'].values[:pn]\n",
    "                \n",
    "            model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=pn, \n",
    "                                      mu_peaks=pl, pmodel=conf['prior_model'])\n",
    "        else:\n",
    "            model_g = mdl.model_gauss(xvalues=x_val, observations=y_val[i], npeaks=pn,\n",
    "                                      pmodel=conf['prior_model'])      \n",
    "        models.append(model_g)\n",
    "\n",
    "        with model_g:\n",
    "            if conf['model_mode'] == 'train':\n",
    "                print(\"({2}/{3}) running inference on dataset #{0}/{1} [{4}-peak model:{5}-peak spectrum]\"\n",
    "                      .format(i+1,len(ldata),run,truns,pn,len(plist)))\n",
    "                lmodpeak += [(pn,len(plist))]\n",
    "                trace_g = pm.sample(conf['nsamples'], init=conf['init_mode'], cores=conf['ncores'])\n",
    "                traces.append(trace_g)\n",
    "                # save inference results\n",
    "                pm.backends.text.dump(out_path + '/traces_%02d' % (run), trace_g)\n",
    "            else:\n",
    "                # load traces from disk\n",
    "                print(\"loading dataset #{0}/{1}\".format(run,truns))\n",
    "                trace_g = pm.backends.text.load(out_path + '/traces_%02d' % (run))\n",
    "                traces.append(trace_g)\n",
    "            run += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model figure as image\n",
    "img = pm.model_to_graphviz(models[0])\n",
    "img.render(filename=file_basename + '_model', format='png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive traces\n",
    "ppc = [pm.sample_posterior_predictive(traces[i], samples=500, model=models[i]) for i in range(len(traces))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# various plots to inspect the inference results\n",
    "varnames = ['amp', 'mu', 'sigma', 'epsilon']\n",
    "\n",
    "#az.plot_trace(traces[2], varnames, compact=True);\n",
    "#az.plot_trace(traces[2], varnames, divergences='top');\n",
    "#az.plot_autocorr(traces[0], varnames);\n",
    "#az.plot_posterior(traces[2], varnames);\n",
    "\n",
    "#for idx, trace in enumerate(traces):\n",
    "#    az.plot_forest(trace, var_names = varnames, r_hat=True, ess=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if conf['model_mode'] == 'train':\n",
    "    # collect the results and display\n",
    "    df = res.get_results_summary(varnames, traces, ppc, y_val, epsilon_real=0.05, sets=tsets, labels=lmodpeak)\n",
    "else:\n",
    "    # load results from disk\n",
    "    df = pd.read_csv(file_basename + '.csv')\n",
    "    df.index += 1\n",
    "#df.sort_values(by=['r2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['model_mode'] == 'train':\n",
    "    # save results to .csv\n",
    "    df.to_csv(file_basename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(int(truns/2),2), figure_size=(12,int(truns*(1.8))),\n",
    "                    savefig='yes', fname=file_basename, showpeaks='no', sets=tsets, labels=lmodpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(int(truns/2),2), figure_size=(12,int(truns*(1.8))),\n",
    "                    savefig='yes', fname=file_basename, showpeaks='yes', sets=tsets, labels=lmodpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.close(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
