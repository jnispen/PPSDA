{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario D - Peakshape Variation\n",
    "\n",
    "In this scenario the peakshape in a spectrum with a fixed number of peaks is varied from Gaussian (n = 0.0) to Lorentzian (n = 1.0). All datasets contain 3 peaks and the noise level is kept constant at 1%.\n",
    "\n",
    "The model used in the inference of the parameters is formulated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large y = f(x) = \\sum\\limits_{m=1}^M \\big[A_m \\cdot f_{pseudo-Voigt}(x)\\big] + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large f_{pseudo-Voigt}(x) = \\eta \\cdot \\frac{\\sigma_m}{(x-\\mu_m)^2 + \\sigma_m^2} + (1 - \\eta) \\cdot e^{-\\frac{(x-\\mu_m)^2}{2\\cdot\\sigma_m^2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "#az.style.use('arviz-darkgrid')\n",
    "\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../modules')\n",
    "import datagen as dg\n",
    "import models as mdl\n",
    "import results as res\n",
    "import figures as fig\n",
    "import settings as cnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for results and images\n",
    "out_path      = './output_peakshape'\n",
    "file_basename = out_path + '/scenario_peakshape'\n",
    "        \n",
    "conf = {}\n",
    "    \n",
    "# scenario name\n",
    "conf['scenario'] = 'peakshape variation'\n",
    "    \n",
    "# initialization method for sampler\n",
    "conf['init_mode'] = 'adapt_diag'\n",
    "\n",
    "# probabilistic model (priors)\n",
    "conf['prior_model'] = 'lognormal'\n",
    "\n",
    "# provide peak positions to the model as testvalues ('yes'/'no')\n",
    "conf['peak_info'] = 'yes'\n",
    "\n",
    "# model mode ('train'/eval')\n",
    "conf['model_mode'] = 'train'\n",
    "\n",
    "# data mode ('generate'/'preload')\n",
    "conf['data_mode'] = 'generate'\n",
    "\n",
    "# dataset directory (needed for 'preload' data mode)\n",
    "#conf['dataset_dir'] = './input_datasets'\n",
    "\n",
    "# number of cores to run sampling chains on\n",
    "conf['ncores'] = 2\n",
    "\n",
    "# number of samples per chain\n",
    "conf['nsamples'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the output dir does not exist, create it\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.save(out_path, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of wavelengths (x-values)\n",
    "xval = [i for i in range(200, 400, 2)]\n",
    "\n",
    "ldata  = []\n",
    "lpeaks = []\n",
    "lpeakshape = []\n",
    "\n",
    "# number of spectra per baseline variation\n",
    "nsets  = 1\n",
    "\n",
    "# peakshape weight factors (0 = Gauss, 1 = Lorentz)\n",
    "#peakshapes = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "peakshapes = [0.0, 0.5, 1.0]\n",
    "lpeakshape = [ps for ps in peakshapes for i in range(nsets)]\n",
    "\n",
    "# total number of datasets\n",
    "tsets = nsets * len(peakshapes)\n",
    "        \n",
    "if conf['model_mode'] == 'train' and conf['data_mode'] == 'generate':\n",
    "    # generate the datasets\n",
    "    for ps in peakshapes:\n",
    "        for i in range(nsets):\n",
    "            df, peaks, _ = dg.data_generator(xvalues=xval, nsamples=15, npeaks=3, peakshape=ps)\n",
    "            ldata.append(df)\n",
    "            lpeaks.append(peaks)\n",
    "    # save data and peak information to disk\n",
    "    for i in range(len(ldata)):\n",
    "        ldata[i].to_csv(out_path + '/dataset_%02d.csv' % (i+1), index=False)\n",
    "    dg.data_save(out_path + '/peakinfo.csv', lpeaks)\n",
    "        \n",
    "elif conf['model_mode'] == 'train' and conf['data_mode'] == 'preload':           \n",
    "    # load pre-generated datasets from disk\n",
    "    ldata, lpeaks, _ = dg.data_load(tsets, conf['dataset_dir'])\n",
    "    \n",
    "else:        \n",
    "    # load data from disk\n",
    "    if conf['data_mode'] == 'preload':\n",
    "        ldata, lpeaks, _ = dg.data_load(tsets, conf['dataset_dir'])\n",
    "    else:\n",
    "        ldata, lpeaks, _ = dg.data_load(tsets, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"total number of peakshape variations    : {0}\".format(len(peakshapes)))\n",
    "print(\"total number of datasets per peakshape  : {0}\".format(nsets))\n",
    "print(\"total number of datasets per model      : {0}\".format(tsets))\n",
    "print(\"total number of inference runs          : {0}\".format(nsets*len(peakshapes)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot datasets\n",
    "#fig.plot_datasets(ldata, lpeaks, dims=(int(tsets/2),2), figure_size=(12,int(tsets*(1.8))), \n",
    "#                            savefig='yes', fname=file_basename, scenario='peakshape', labels=lpeakshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas data to numpy arrays\n",
    "x_val = np.array(xval, dtype='float32')\n",
    "\n",
    "# store dataset y-values in list\n",
    "cols = ldata[0].columns\n",
    "y_val = [ldata[i][cols].values for i in range(len(ldata))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize models and run inference\n",
    "models = []\n",
    "traces = []\n",
    "\n",
    "# list of tuples with (model peakshape, data peakshape) combination\n",
    "lmodbase = []\n",
    "\n",
    "# actual run number\n",
    "run = 1\n",
    "\n",
    "# total number of inference runs\n",
    "truns = nsets * len(peakshapes)**2\n",
    "\n",
    "for ps in peakshapes:\n",
    "    if conf['model_mode'] == 'train':\n",
    "        # for each baseline model run inference on all spectra\n",
    "        print(\"running: n = {0} peakshape model\".format(ps))\n",
    "    \n",
    "    for i in range(len(ldata)):\n",
    "        if conf['peak_info'] == 'yes':\n",
    "            plist = lpeaks[i].flatten()\n",
    "            plist.sort()\n",
    "            model_g = mdl.model_pvoigt(xvalues=x_val, observations=y_val[i], npeaks=3, peakshape=ps,\n",
    "                                  mu_peaks=plist, pmodel=conf['prior_model'])\n",
    "        else:\n",
    "            model_g = mdl.model_pvoigt(xvalues=x_val, observations=y_val[i], npeaks=3, peakshape=ps,\n",
    "                                                  pmodel=conf['prior_model'])\n",
    "                \n",
    "        models.append(model_g)\n",
    "\n",
    "        with model_g:\n",
    "            if conf['model_mode'] == 'train':\n",
    "                print(\"({2}/{3}) running inference on dataset #{0}/{1} [{4} model: {5} data]\"\n",
    "                      .format(i+1,len(ldata),run,truns,ps,lpeakshape[i]))\n",
    "                trace_g = pm.sample(conf['nsamples'], init=conf['init_mode'], cores=conf['ncores'])\n",
    "                lmodbase += [(ps,lpeakshape[i])]\n",
    "                traces.append(trace_g)\n",
    "                # save inference results\n",
    "                pm.backends.text.dump(out_path + '/traces_%02d' % (run), trace_g)\n",
    "            else:\n",
    "                # load traces from disk\n",
    "                print(\"loading dataset #{0}/{1}\".format(run,truns))\n",
    "                trace_g = pm.backends.text.load(out_path + '/traces_%02d' % (run))\n",
    "                traces.append(trace_g)\n",
    "            run += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display first model\n",
    "pm.model_to_graphviz(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model figure as image\n",
    "img = pm.model_to_graphviz(models[0])\n",
    "img.render(filename=file_basename + '_model', format='png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive traces\n",
    "ppc = [pm.sample_posterior_predictive(traces[i], samples=500, model=models[i]) for i in range(len(traces))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# various plots to inspect the inference results\n",
    "varnames = mdl.get_varnames(traces[0])\n",
    "\n",
    "#az.plot_trace(traces[2], varnames, compact=True);\n",
    "#az.plot_trace(traces[2], varnames, divergences='top');\n",
    "#az.plot_autocorr(traces[0], varnames);\n",
    "az.plot_posterior(traces[8], varnames);\n",
    "\n",
    "#for idx, trace in enumerate(traces):\n",
    "#    az.plot_forest(trace, var_names = varnames, r_hat=True, ess=True);\n",
    "\n",
    "#az.summary(traces[20], varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if conf['model_mode'] == 'train':\n",
    "    # collect the results and display\n",
    "    df = res.get_results_summary(traces, ppc, y_val, epsilon_real=0.05, sets=tsets, \n",
    "                                 labels=lmodbase, multimodels='yes')\n",
    "else:\n",
    "    # load results from disk\n",
    "    df = pd.read_csv(file_basename + '.csv')\n",
    "    df.index += 1\n",
    "    \n",
    "    # create list of tuples with model/data combinations\n",
    "    lm = df['model'].to_list()\n",
    "    ld = df['data'].to_list()\n",
    "    lmodbase = list(zip(lm,ld))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['model_mode'] == 'train':\n",
    "    # save results to .csv\n",
    "    df.to_csv(file_basename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(fig)\n",
    "\n",
    "#fig.plot_posterior(x_val, ldata, traces, ppc, dims=(int(truns/2),2), figure_size=(12,int(truns*(1.8))),\n",
    "#            savefig='yes', fname=file_basename, showpeaks='no', sets=tsets, labels=lmodbase, scenario='baseline')\n",
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(5,2), figure_size=(12,int(truns*(1.8))),\n",
    "            savefig='yes', fname=file_basename, showpeaks='no', sets=tsets, labels=lmodbase, scenario='baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fig.plot_posterior(x_val, ldata, traces, ppc, dims=(int(truns/2),2), figure_size=(12,int(truns*(1.8))),\n",
    "#            savefig='yes', fname=file_basename, showpeaks='yes', sets=tsets, labels=lmodbase, scenario='baseline')\n",
    "fig.plot_posterior(x_val, ldata, traces, ppc, dims=(5,2), figure_size=(12,int(truns*(2.5))),\n",
    "            savefig='yes', fname=file_basename, showpeaks='yes', sets=tsets, labels=lmodbase, scenario='baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.close(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
